# üöÄ Architecture Kubernetes - VidP Microservices

## Vue d'ensemble

Ce document d√©crit l'architecture de d√©ploiement de VidP sur Kubernetes, refl√©tant l'organisation actuelle du projet o√π chaque microservice est d√©ploy√© sur des pods d√©di√©s.

## üèóÔ∏è Architecture de Production

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                            Kubernetes Cluster                                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Namespace: vidp                                                                                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                                      Ingress (vidp.local, api.vidp.local)                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îÇ                                        ‚îÇ                                                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ       ‚îÇ Frontend (Next.js)         ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚ñ∂‚îÇ Main-App (FastAPI Orchestrator)  ‚îÇ                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ       ‚îÇ   (vidp.local:3000)        ‚îÇ    ‚îÇ    ‚îÇ    (api.vidp.local:8000)         ‚îÇ                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                         ‚îÇ                     ‚îÇ (HTTP POST - Upload file)               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                         ‚îÇ                     ‚ñº                                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ animal-detect             ‚îÇ  ‚îÇ downscale ‚îÇ  ‚îÇ langscale ‚îÇ  ‚îÇ subtitle  ‚îÇ  ‚îÇ mongodb               ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   (Service: :8004)        ‚îÇ  ‚îÇ (Service: ‚îÇ  ‚îÇ (Service: ‚îÇ  ‚îÇ (Service: ‚îÇ  ‚îÇ   (Service: :27017)   ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   (emptyDir)              ‚îÇ  ‚îÇ  :8001)   ‚îÇ  ‚îÇ  :8002)   ‚îÇ  ‚îÇ  :8003)   ‚îÇ  ‚îÇ   (PVC)               ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üéØ Principe cl√© : Upload de fichiers, pas de partage de chemins

### ‚ùå Ce qui NE fonctionne PAS en production

```python
# MAUVAISE approche (d√©veloppement local uniquement)
payload = {
    "video_path": "/local_storage/videos/abc123.mp4"  # ‚ö†Ô∏è N'existe que sur Pod A!
}
response = await client.post("http://langscale:8002/api/detect/local", json=payload)
```

**Probl√®me** : Le Pod `langscale` (Pod B) ne peut pas acc√©der au chemin de fichier du `main-app` (Pod A) sans un syst√®me de fichiers partag√©.

### ‚úÖ Solution impl√©ment√©e

```python
# BONNE approche (fonctionne en d√©veloppement ET production)
with open(video_path, 'rb') as video_file:
    files = {'file': (filename, video_file, 'video/mp4')}
    data = {'duration': '30', 'test_all_languages': 'true'}
    response = await client.post(
        "http://langscale-service:8002/api/detect/upload", # Utilisation du service K8s DNS
        files=files,
        data=data
    )
```

**Avantage** : Le fichier est envoy√© via HTTP, ind√©pendamment de l'emplacement des pods.

## üìÅ Gestion du stockage en Kubernetes

Notre architecture privil√©gie l'**Upload HTTP** pour le transfert de fichiers entre microservices. Pour le stockage persistant, seul MongoDB utilise un PersistentVolumeClaim (PVC). Les autres microservices utilisent des `emptyDir` pour leur stockage temporaire, ce qui signifie que les donn√©es sont √©ph√©m√®res et li√©es au cycle de vie du pod.

### PersistentVolumeClaim (PVC) pour MongoDB

```yaml
# mongodb-pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mongodb-pvc
  namespace: vidp
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
```

### Stockage √âph√©m√®re (emptyDir) pour les Microservices

```yaml
# Exemple pour main-app et d'autres microservices
volumeMounts:
  - name: video-storage
    mountPath: /app/local_storage
volumes:
  - name: video-storage
    emptyDir: {} # Les donn√©es sont perdues si le pod red√©marre
```

## üîÑ Flux de traitement en production

### √âtape 1 : Upload initial d'une vid√©o via Frontend
```
Client (Navigateur) ‚Üí Ingress ‚Üí Frontend ‚Üí Main-App
‚îÇ
‚îî‚îÄ> Main-App sauvegarde la vid√©o dans son emptyDir local
    ‚îî‚îÄ> Main-App enregistre les m√©tadonn√©es vid√©o dans MongoDB
```

### √âtape 2 : D√©tection de langue
```
Main-App ‚Üí langscale (via HTTP POST)
‚îÇ
‚îú‚îÄ> Main-App lit le fichier depuis son emptyDir
‚îú‚îÄ> Main-App upload le fichier via HTTP multipart/form-data au service langscale
‚îî‚îÄ> langscale traite et retourne le r√©sultat (langue d√©tect√©e)
    ‚îî‚îÄ> Main-App sauvegarde le r√©sultat de la d√©tection de langue dans MongoDB
```

### √âtape 3 : Compression (exemple)
```
Main-App ‚Üí downscale (via HTTP POST)
‚îÇ
‚îú‚îÄ> Main-App lit le fichier depuis son emptyDir
‚îú‚îÄ> Main-App upload le fichier via HTTP multipart/form-data au service downscale
‚îî‚îÄ> downscale compresse la vid√©o et retourne l'URL du fichier compress√©
    ‚îî‚îÄ> Main-App sauvegarde l'URL du fichier compress√© et les m√©tadonn√©es dans MongoDB
```
Ce flux est appliqu√© de mani√®re similaire pour les services `subtitle` et `animal-detect`.

## üõ†Ô∏è Configuration Kubernetes (Exemples Simplifi√©s)

Chaque service est configur√© via des Deployments et Services. Les configurations sont g√©r√©es par Kustomize dans le r√©pertoire `k8s/`.

### Namespace

```yaml
# namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: vidp
  labels:
    app: vidp
    environment: development
```

### ConfigMaps et Secrets

Les variables d'environnement des microservices sont g√©r√©es par ConfigMaps et Secrets.

```yaml
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: vidp-config
  namespace: vidp
data:
  LANGSCALE_SERVICE_URL: "http://langscale-service:8002"
  DOWNSCALE_SERVICE_URL: "http://downscale-service:8001"
  SUBTITLE_SERVICE_URL: "http://subtitle-service:8003"
  ANIMAL_DETECTION_SERVICE_URL: "http://animal-detect-service:8004"
  APP_NAME: "VidP Kubernetes API"
  CORS_ORIGINS: '["http://localhost:3000","http://frontend-service:3000","*"]'
  # ... autres configs
```

```yaml
# k8s/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: vidp-secrets
  namespace: vidp
type: Opaque
stringData:
  MONGODB_USERNAME: "vidp_admin"
  MONGODB_PASSWORD: "vidp_password_2024"
  MONGODB_URL: "mongodb://vidp_admin:vidp_password_2024@mongodb-service:27017/vidp_db?authSource=admin"
```

### Ingress (Exposition externe)

L'Ingress permet d'exposer les services `frontend` et `main-app` via des noms de domaine locaux (`vidp.local`, `api.vidp.local`).

```yaml
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: vidp-ingress
  namespace: vidp
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/proxy-body-size: "500m" # Taille max upload
    nginx.ingress.kubernetes.io/proxy-read-timeout: "9000"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "9000"
spec:
  ingressClassName: nginx
  rules:
    - host: vidp.local # Acc√®s au Frontend
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: frontend-service
                port:
                  number: 3000
    - host: api.vidp.local # Acc√®s √† l'API principale
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: main-app-service
                port:
                  number: 8000
```

## üìä Avantages de notre architecture

### ‚úÖ Scalabilit√©
- Chaque service peut scaler ind√©pendamment en ajustant le nombre de `replicas`.
- Exemple : `kubectl scale deployment langscale -n vidp --replicas=5`

### ‚úÖ Isolation
- Un crash ou un probl√®me dans un microservice n'affecte pas directement les autres.
- Les mises √† jour peuvent √™tre effectu√©es de mani√®re ind√©pendante (rolling updates).

### ‚úÖ Flexibilit√©
- Fonctionne avec des stockages `emptyDir` pour l'√©ph√©m√®re et `PVC` pour la persistance.
- La communication via HTTP est un protocole standard et flexible.

### ‚úÖ Monitoring
- Le `kube-prometheus-stack` est configur√© pour collecter les m√©triques de tous les pods dans le namespace `vidp`.
- Exemple de `ServiceMonitor` (implicite dans Prometheus Operator pour les deployments standard) :
```yaml
# Exemple (ServiceMonitor n'est pas cr√©√© manuellement dans les YAMLs fournis,
# mais est g√©r√© automatiquement par Prometheus Operator pour les services K8s)
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: vidp-metrics-main-app
  namespace: vidp
spec:
  selector:
    matchLabels:
      app: main-app
  endpoints:
  - port: http # Doit correspondre √† un nom de port dans le Service
    path: /health # Ou un endpoint de m√©triques si disponible
```

## üîç Communication inter-services

### DNS interne Kubernetes
Les microservices communiquent entre eux en utilisant le DNS interne de Kubernetes. Par exemple, `main-app` acc√®de √† `langscale` via son nom de service.

```python
# Dans vidp-main-app
# La variable d'environnement LANGSCALE_SERVICE_URL est configur√©e via ConfigMap
# LANGSCALE_SERVICE_URL: "http://langscale-service:8002"
#                                   ^^^^^^^^^^^^^^
#                                 Nom du Service K8s
```

### Service Discovery automatique
- Le DNS de Kubernetes r√©sout automatiquement `langscale-service` en l'adresse IP du Service correspondant.
- Le load balancing automatique est appliqu√© entre les pods du service cible.

## üìà Performance et optimisation

### 1. Limites et Requ√™tes de ressources (Resource Requests/Limits)
D√©finir des requ√™tes et limites de CPU et m√©moire aide √† la stabilit√© du cluster et √† l'allocation des ressources.

```yaml
resources:
  requests:
    memory: "256Mi"
    cpu: "250m"
  limits:
    memory: "512Mi"
    cpu: "500m"
```
*(Exemple g√©n√©rique, les valeurs r√©elles sont d√©finies par service dans `k8s/*.yaml`)*

### 2. Readiness & Liveness Probes
Ces sondes garantissent que les pods sont sains et pr√™ts √† recevoir du trafic.

```yaml
# Exemple de livenessProbe pour main-app
livenessProbe:
  httpGet:
    path: /health
    port: 8000
  initialDelaySeconds: 15
  periodSeconds: 20

# Exemple de readinessProbe pour main-app
readinessProbe:
  httpGet:
    path: /health
    port: 8000
  initialDelaySeconds: 5
  periodSeconds: 10
```

### 3. Horizontal Pod Autoscaling (HPA)
Bien que non activ√© par d√©faut dans les `k8s/*.yaml` fournis, l'architecture supporte le HPA pour scaler les pods en fonction de la charge CPU/m√©moire.

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: vidp-main-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: main-app # Cible le d√©ploiement main-app
  minReplicas: 1 # R√©plicas minimum (actuellement 1)
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

## üöÄ D√©ploiement

Le d√©ploiement de l'application VidP dans le cluster Kubernetes `vidp` est orchestr√© via Kustomize (`k8s/kustomization.yaml`).

```bash
# S'assurer que le namespace est cr√©√©
kubectl create namespace vidp

# Appliquer tous les manifestes Kubernetes via Kustomize
kubectl apply -k k8s/

# Alternativement, appliquer les fichiers individuellement dans l'ordre de d√©pendance:
# 1. Namespace (cr√©√© par kustomize ou manuellement)
# kubectl apply -f k8s/namespace.yaml

# 2. ConfigMaps et Secrets
# kubectl apply -f k8s/configmap.yaml
# kubectl apply -f k8s/secrets.yaml

# 3. D√©ployer MongoDB (PVC d'abord)
# kubectl apply -f k8s/mongodb.yaml

# 4. D√©ployer les microservices et le frontend
# kubectl apply -f k8s/animal-detect.yaml
# kubectl apply -f k8s/downscale.yaml
# kubectl apply -f k8s/langscale.yaml
# kubectl apply -f k8s/subtitle.yaml
# kubectl apply -f k8s/main-app.yaml
# kubectl apply -f k8s/frontend.yaml

# 5. Configurer l'Ingress
# kubectl apply -f k8s/ingress.yaml

# 6. V√©rifier les pods
kubectl get pods -n vidp
```

## üéØ Conclusion

Notre impl√©mentation actuelle est con√ßue pour √™tre compatible avec Kubernetes :
- ‚úÖ Pas de d√©pendance sur chemins de fichiers locaux partag√©s entre pods.
- ‚úÖ Communication inter-services via HTTP standard et DNS interne Kubernetes.
- ‚úÖ Configuration externalis√©e via ConfigMaps et Secrets.
- ‚úÖ Services ind√©pendants et largement stateless (√† l'exception de MongoDB).
- ‚úÖ Utilisation de `emptyDir` pour le stockage temporaire des microservices.

---