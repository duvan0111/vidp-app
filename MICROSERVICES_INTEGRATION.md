# üéØ Int√©gration compl√®te des microservices VidP

## Vue d'ensemble

Ce document d√©crit l'int√©gration et le flux de communication entre les diff√©rents microservices de traitement vid√©o et l'application principale `vidp-main-app`, qui agit comme orchestrateur central. L'architecture est con√ßue pour √™tre modulaire et √©volutive, ind√©pendamment de la plateforme d'orchestration (comme Kubernetes).

## üèóÔ∏è Architecture des Microservices VidP

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                  VidP Main App (Orchestrateur)                                  ‚îÇ
‚îÇ                 Manages workflow, data persistence (MongoDB), and external API                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                                                ‚îÇ
‚îÇ  1. Upload Vid√©o (via API) ‚Üí Stockage temporaire + M√©tadonn√©es MongoDB                         ‚îÇ
‚îÇ  2. Orchestration des traitements (chaque √©tape re√ßoit la vid√©o via HTTP POST) :               ‚îÇ
‚îÇ     ‚îú‚îÄ> √âtape 1: D√©tection de langue (app_langscale)                                           ‚îÇ
‚îÇ     ‚îú‚îÄ> √âtape 2: Compression vid√©o (app_downscale)                                             ‚îÇ
‚îÇ     ‚îú‚îÄ> √âtape 3: G√©n√©ration de sous-titres (app_subtitle)                                      ‚îÇ
‚îÇ     ‚îú‚îÄ> √âtape 4: D√©tection d'animaux (app_animal_detect)                                       ‚îÇ
‚îÇ     ‚îî‚îÄ> √âtape 5: Agr√©gation vid√©o (service d'agr√©gation cloud-hosted)                          ‚îÇ
‚îÇ  3. Stockage des r√©sultats de chaque √©tape ‚Üí MongoDB                                            ‚îÇ
‚îÇ  4. R√©cup√©ration des m√©tadonn√©es compl√®tes et streaming de la vid√©o finale                     ‚îÇ
‚îÇ                                                                                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ                 ‚îÇ
          ‚îÇ HTTP Upload   ‚îÇ HTTP Upload    ‚îÇ HTTP Upload    ‚îÇ HTTP Upload     ‚îÇ HTTP Upload
          ‚ñº               ‚ñº                ‚ñº                ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  app_langscale    ‚îÇ ‚îÇ  app_downscale    ‚îÇ ‚îÇ  app_subtitle     ‚îÇ ‚îÇ  app_animal_detect‚îÇ ‚îÇ  Aggregation      ‚îÇ
‚îÇ   (Port 8002)     ‚îÇ ‚îÇ   (Port 8001)     ‚îÇ ‚îÇ   (Port 8003)     ‚îÇ ‚îÇ   (Port 8004)     ‚îÇ ‚îÇ   (Cloud-hosted)  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ D√©tection langue‚îÇ ‚îÇ ‚Ä¢ Compression     ‚îÇ ‚îÇ ‚Ä¢ Whisper AI      ‚îÇ ‚îÇ ‚Ä¢ YOLOv8          ‚îÇ ‚îÇ ‚Ä¢ Burn Subtitles  ‚îÇ
‚îÇ ‚Ä¢ Google Speech   ‚îÇ ‚îÇ ‚Ä¢ FFmpeg          ‚îÇ ‚îÇ ‚Ä¢ G√©n√©ration SRT  ‚îÇ ‚îÇ ‚Ä¢ Animal Detection‚îÇ ‚îÇ ‚Ä¢ Combine Streams ‚îÇ
‚îÇ ‚Ä¢ 15 langues      ‚îÇ ‚îÇ ‚Ä¢ 240p-1080p      ‚îÇ ‚îÇ ‚Ä¢ Multi-langues   ‚îÇ ‚îÇ ‚Ä¢ Image/Video     ‚îÇ ‚îÇ ‚Ä¢ Final Output    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üéØ Services int√©gr√©s

Le `vidp-main-app` orchestre les flux de traitement en communiquant avec les microservices suivants via des requ√™tes HTTP (g√©n√©ralement des uploads de fichiers).

### 1. **D√©tection de langue** (`app_langscale`)

**R√¥le** : D√©tecte la langue parl√©e dans la piste audio d'une vid√©o.
**Endpoint principal** : `POST /api/detect/upload`
**Fonctionnalit√©s** :
-   D√©tection automatique de la langue parl√©e (plus de 15 langues).
-   Utilisation de la reconnaissance vocale pour l'analyse.
-   Retourne la langue d√©tect√©e avec un niveau de confiance.

**Exemple de Requ√™te (`vidp-main-app` vers `app_langscale`)** :
```python
# Fichier vid√©o envoy√© via HTTP multipart/form-data
response = await client.post(
    f"{settings.langscale_service_url}/api/detect/upload",
    files={'file': ('video.mp4', video_data, 'video/mp4')},
    data={'duration': '30', 'test_all_languages': 'true'}
)
```
**Exemple de R√©ponse** :
```json
{
  "status": "completed",
  "detected_language": "fr",
  "language_name": "French",
  "confidence": 0.98
}
```

### 2. **Compression vid√©o** (`app_downscale`)

**R√¥le** : Compresse les vid√©os √† diff√©rentes r√©solutions et niveaux de qualit√©.
**Endpoint principal** : `POST /api/compress/upload`
**Fonctionnalit√©s** :
-   Compression multi-r√©solution (240p, 360p, 480p, 720p, 1080p).
-   Contr√¥le de qualit√© via CRF (Constant Rate Factor).
-   R√©duit significativement la taille des fichiers vid√©o.

**Exemple de Requ√™te (`vidp-main-app` vers `app_downscale`)** :
```python
# Fichier vid√©o envoy√© via HTTP multipart/form-data
response = await client.post(
    f"{settings.downscale_service_url}/api/compress/upload",
    files={'file': ('video.mp4', video_data, 'video/mp4')},
    data={'resolution': '720p', 'crf_value': '23'}
)
```
**Exemple de R√©ponse** :
```json
{
  "status": "completed",
  "output_path": "/path/to/compressed_video.mp4",
  "metadata": {"original_size": "100MB", "final_size_mb": 25.0}
}
```

### 3. **G√©n√©ration de sous-titres** (`app_subtitle`)

**R√¥le** : G√©n√®re automatiquement des sous-titres (SRT) √† partir de la piste audio d'une vid√©o.
**Endpoint principal** : `POST /api/generate-subtitles/`
**Fonctionnalit√©s** :
-   Transcription audio vers texte via Whisper AI (OpenAI).
-   Support de plusieurs mod√®les Whisper (tiny, base, small, medium, large).
-   G√©n√®re des fichiers SRT standardis√©s.

**Exemple de Requ√™te (`vidp-main-app` vers `app_subtitle`)** :
```python
# Fichier vid√©o envoy√© via HTTP multipart/form-data
response = await client.post(
    f"{settings.subtitle_service_url}/api/generate-subtitles/",
    files={'video': ('video.mp4', video_data, 'video/mp4')},
    data={'model_name': 'base', 'language': 'fr'}
)
```
**Exemple de R√©ponse** :
```json
{
  "status": "success",
  "srt_url": "http://subtitle-service:8003/api/download-subtitles/subtitles_xyz.srt",
  "full_text": "Transcription compl√®te..."
}
```

### 4. **D√©tection d'animaux** (`app_animal_detect`)

**R√¥le** : D√©tecte et identifie des animaux (et autres objets) dans des vid√©os ou des images.
**Endpoint principal** : `POST /detect`
**Fonctionnalit√©s** :
-   Utilise le mod√®le YOLOv8 pour la d√©tection en temps r√©el.
-   Capable de d√©tecter un large √©ventail d'esp√®ces animales (bas√© sur le dataset COCO).
-   Fournit des informations sur les objets d√©tect√©s par image ou par vid√©o.

**Exemple de Requ√™te (`vidp-main-app` vers `app_animal_detect`)** :
```python
# Fichier vid√©o envoy√© via HTTP multipart/form-data
response = await client.post(
    f"{settings.animal_detection_service_url}/detect",
    files={'file': ('video.mp4', video_data, 'video/mp4')},
    params={'confidence_threshold': 0.5, 'save_video': 'true'}
)
```
**Exemple de R√©ponse** :
```json
{
  "status": "completed",
  "video_info": {"duration_seconds": 60, ...},
  "detection_summary": {"animals_detected": {"dog": 5, "cat": 2}, ...},
  "output_video": "base64_encoded_image_or_url"
}
```

### 5. **Service d'agr√©gation vid√©o** (`Aggregation Service`)

**R√¥le** : Combine la vid√©o trait√©e avec les sous-titres g√©n√©r√©s (et d'autres m√©tadonn√©es) pour produire une vid√©o finale avec incrustation des sous-titres ("burned-in subtitles"). Ce service est h√©berg√© dans le cloud et est le dernier point du pipeline de traitement.
**Endpoint principal** : `POST /api/process-video/`
**Fonctionnalit√©s** :
-   Incrustation de sous-titres SRT dans la vid√©o.
-   Peut combiner diff√©rentes sorties des autres microservices (vid√©o compress√©e, sous-titres, informations de d√©tection d'animaux, langue d√©tect√©e).
-   G√©n√®re une URL de streaming pour la vid√©o finale.

**Exemple de Requ√™te (`vidp-main-app` vers `Aggregation Service`)** :
```python
# Fichiers vid√©o et SRT envoy√©s via HTTP multipart/form-data
response = await client.post(
    f"{settings.aggregation_service_url}/api/process-video/",
    files={
        'video': ('compressed_video.mp4', compressed_video_data, 'video/mp4'),
        'srt_file': ('subtitles.srt', srt_data, 'text/plain')
    },
    data={
        'resolution': '720p',
        'crf_value': '23',
        'detected_language': 'fr',
        'animals_detected': '{"dog": 5}'
    }
)
```
**Exemple de R√©ponse** :
```json
{
  "status": "completed",
  "video_id": "agg_xyz",
  "streaming_url": "http://cloud-storage/agg_video.mp4",
  "message": "Agr√©gation termin√©e"
}
```

## üì° Endpoints d'orchestration (`vidp-main-app`)

Le `vidp-main-app` expose des endpoints pour l'upload initial et pour lancer le **workflow global de traitement**.

### Upload et gestion des vid√©os initiales

| M√©thode | Endpoint | Description |
|---------|----------|-------------|
| `POST` | `/api/v1/videos/upload` | Upload une vid√©o initiale √† `vidp-main-app` |
| `GET` | `/api/v1/videos/{video_id}` | R√©cup√®re les m√©tadonn√©es d'une vid√©o |
| `GET` | `/api/v1/videos/` | Liste toutes les vid√©os |
| `GET` | `/api/v1/videos/stream/{video_id}` | Streamer une vid√©o brute (avant traitement) |

### Orchestration des traitements (Endpoints du `vidp-main-app`)

| M√©thode | Endpoint | Description |
|---------|----------|-------------|
| `POST` | `/api/v1/processing/process-video` | **Lance le workflow global de traitement** (d√©tection langue, compression, sous-titres, d√©tection animaux, agr√©gation) |
| `GET` | `/api/v1/processing/process-video/{video_id}` | R√©cup√®re les r√©sultats du workflow global pour une vid√©o |
| `GET` | `/api/v1/processing/language-detection/{video_id}` | R√©sultat d√©tection langue |
| `GET` | `/api/v1/processing/compression/{video_id}` | R√©sultat compression vid√©o |
| `GET` | `/api/v1/processing/subtitles/{video_id}` | R√©sultat g√©n√©ration sous-titres |
| `GET` | `/api/v1/processing/animal-detection/{video_id}` | R√©sultat d√©tection d'animaux |
| `GET` | `/api/v1/processing/supported-languages` | Langues support√©es par `app_langscale` |
| `GET` | `/api/v1/processing/health` | Sant√© de tous les microservices |

### Statut et sant√© globaux

| M√©thode | Endpoint | Description |
|---------|----------|-------------|
| `GET` | `/health` | Sant√© globale de l'API `vidp-main-app` |
| `GET` | `/api/v1/status/health` | Statut d√©taill√© de `vidp-main-app` |

## üîÑ Workflow de traitement complet (via `/api/v1/processing/process-video`)

Ce workflow est orchestr√© par le `vidp-main-app` et encha√Æne les appels aux microservices. Chaque √©tape utilise la vid√©o trait√©e de l'√©tape pr√©c√©dente ou l'originale si pas de modification.

```mermaid
graph TD
    A[Client Uploads Video] --> B(vidp-main-app: /api/v1/videos/upload)
    B --> C{Save Video to Local Temp Storage<br>+ Record Metadata in MongoDB}
    C --> D(vidp-main-app: /api/v1/processing/process-video)
    D --> E{Check Audio Track}
    E -- Has Audio --> F(Call app_langscale: Language Detection)
    E -- No Audio --> F_SKIP[Skip Language Detection]
    F --> G(Record Language Detection Result in MongoDB)
    F_SKIP --> G

    G --> H(Call app_downscale: Video Compression)
    H --> I(Record Compression Result in MongoDB)

    I --> J{Check Audio Track}
    J -- Has Audio --> K(Call app_subtitle: Subtitle Generation)
    J -- No Audio --> K_SKIP[Skip Subtitle Generation<br>(Generate empty SRT)]
    K --> L(Record Subtitle Result in MongoDB)
    K_SKIP --> L

    L --> M(Call app_animal_detect: Animal Detection)
    M --> N(Record Animal Detection Result in MongoDB)

    N --> O(Call Aggregation Service: Final Video Processing)
    O --> P(Record Aggregation Result in MongoDB<br>+ Get Final Streaming URL)
    P --> Q[Return Global Processing Result to Client]
```

## üöÄ D√©marrage des services (D√©veloppement local)

Pour lancer tous les microservices en d√©veloppement local :

```bash
# S'assurer que MongoDB est d√©marr√© (ex: via Docker)
docker-compose up -d mongodb

# Utiliser le script de d√©marrage global du projet
./start_all_services.sh
```

## üìä Architecture MongoDB

### Collections g√©r√©es par `vidp-main-app`

#### 1. `video_metadata`
Stocke les m√©tadonn√©es initiales de chaque vid√©o upload√©e, ainsi que les statuts de traitement globaux.

**Exemple** :
```json
{
  "video_id": "abc123",
  "original_filename": "video.mp4",
  "file_path": "/app/local_storage/videos/abc123.mp4",
  "file_size": 52428800,
  "content_type": "video/mp4",
  "status": "processing",
  "upload_time": "2026-01-02T10:00:00",
  "current_stage": "animal_detection",
  "stages_completed": ["language_detection", "compression", "subtitle_generation"],
  "stages_failed": []
}
```

#### 2. `processing_results`
Stocke les r√©sultats d√©taill√©s de chaque √©tape de traitement (langue, compression, sous-titres, d√©tection animale, agr√©gation) pour chaque `video_id`.

**Exemple (D√©tection de langue)** :
```json
{
  "video_id": "abc123",
  "processing_type": "language_detection",
  "result": {
    "job_id": "lang456",
    "detected_language": "fr",
    "language_name": "French",
    "confidence": 0.98,
    "processing_time": 12.34
  },
  "updated_at": "2026-01-02T10:05:00"
}
```

## üîí S√©curit√© et bonnes pratiques

### 1. Validation des entr√©es
‚úÖ Toutes les requ√™tes API sont valid√©es avec Pydantic.
‚úÖ V√©rification des formats et tailles de fichiers upload√©s.

### 2. Gestion des erreurs
‚úÖ Utilisation de codes HTTP appropri√©s (400, 404, 500, 503).
‚úÖ Messages d'erreur d√©taill√©s pour faciliter le d√©bogage.

### 3. Performance
‚úÖ Timeouts configurables pour les appels inter-microservices.
‚úÖ Gestion des fichiers en streaming ou temporaires pour optimiser la m√©moire.

### 4. Monitoring et Observabilit√©
‚úÖ Chaque microservice expose un endpoint `/health`.
‚úÖ Logs d√©taill√©s avec timestamps pour le d√©bogage et l'audit.

## üìà Performance et temps de traitement

### Estimations (vid√©o 1 minute, Full HD)

| Service | Op√©ration | Temps moyen |
|---------|-----------|-------------|
| **app_langscale** | D√©tection langue (30s audio) | ~10-15s |
| **app_downscale** | Compression 1080p ‚Üí 360p | ~20-30s |
| **app_subtitle** | G√©n√©ration sous-titres (base) | ~30-45s |
| **app_animal_detect** | D√©tection d'animaux (YOLOv8n) | ~20-60s |
| **Aggregation Service** | Incrustation sous-titres | ~10-20s |

**Total pour traitement complet** : ~90-170 secondes (variable selon le contenu vid√©o et les mod√®les)

### Optimisations possibles

1.  **Traitement parall√®le** : Ex√©cuter des √©tapes ind√©pendantes (ex: d√©tection langue et d√©tection d'animaux) en parall√®le.
2.  **Cache** : Mettre en cache les r√©sultats de traitement pour √©viter des recalculs.
3.  **Syst√®me de files d'attente** : Utiliser des syst√®mes comme Celery ou RabbitMQ pour g√©rer des jobs asynchrones et des traitements en arri√®re-plan.

## üêõ D√©pannage

### Service non accessible

```bash
# V√©rifier l'√©tat de tous les services via l'orchestrateur
curl http://localhost:8000/api/v1/processing/health

# Red√©marrer un service sp√©cifique (exemple pour app_langscale)
pkill -f "app_langscale"
cd app_langscale && python main.py # Ou via Docker/Kubernetes si d√©ploy√© ainsi
```

---

**Version** : 2.0  
**Date** : 23 Janvier 2026  
**Auteur** : VidP Team